{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "759SG4TyfbUn",
        "Zj-h4drXD-X9",
        "BY6yifxscfrx",
        "k_ewoagic5jc",
        "70StdqAZa9E9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fr3d1gg/Inteligencia-Artificial/blob/main/Semillero_IA_%26_Data_NLP_semana_03_Actividad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Maestría en Inteligencia Artificial Aplicada**\n",
        "##**Curso: Procesamiento de Lenguaje Natural (NLP)**\n",
        "###Tecnológico de Monterrey\n",
        "###Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## **Adtividad de la Semana 02**\n",
        "###**Introducción al procesamiento de texto.**"
      ],
      "metadata": {
        "id": "759SG4TyfbUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta actividad deberás utilizar los datos del siguiente archivo que se encuentra en Canvas:\n",
        "\n",
        "MNA_NLP_semana_02_Actividad_datos.txt\n",
        "\n",
        "El archivo contiene comentarios en inglés sobre servicios de comida de la página de Yelp: https://www.yelp.com/ .\n",
        "\n",
        "Son mil comentarios y forman parte del conjunto de datos que se encuentra en el Machine Learning Repository de la UCI, llamado \"Sentiment Labelled Sentences\": https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#\n"
      ],
      "metadata": {
        "id": "6ue1YAKx3XDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 1. Cargamos los datos.**   "
      ],
      "metadata": {
        "id": "Zj-h4drXD-X9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar los datos del archivo indicado y obtener una lista de longitud de 1000 strings/comentarios.\n",
        "\n",
        "Por el momento solamente requerimos las bibliotecas de Numpy y re, para el manejo de los arreglos y de las expresiones regulares en Python.\n",
        "\n",
        "En particular, no necesitarás en esta actividad la biblioteca de Pandas.\n",
        "\n",
        "###**NOTA: En esta actividad no debes importar nada más, con estas dos bibliotecas será *suficiente*.**"
      ],
      "metadata": {
        "id": "BY6yifxscfrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subimos el archivo .txt que decargamos previamente y sin el no podemos avanzar con las actividades c:"
      ],
      "metadata": {
        "id": "G1zw2PtTycNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Subir el archivo desde tu computadora\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Selecciona el archivo MNA_NLP_semana_02_Actividad_datos.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "q3k0mdshyEDo",
        "outputId": "65c8922c-9f2b-4486-8ea5-e307066f5d0c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-33d95dc6-7633-4e5b-978c-1ff99455a7fd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-33d95dc6-7633-4e5b-978c-1ff99455a7fd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Semillero IA & Data_NLP_semana_03_Actividad.txt to Semillero IA & Data_NLP_semana_03_Actividad.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np    # importamos Numpy para el manejo de los arreglos.\n",
        "import re             # importamos re para el manejo de las expresiones regulares."
      ],
      "metadata": {
        "id": "OJ26dAfhdFnf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Semillero IA & Data_NLP_semana_03_Actividad.txt', mode='r') as f:\n",
        "    docs = f.readlines()\n",
        "\n",
        "docs = [line.strip() for line in docs]\n",
        "\n",
        "\n",
        "print(f\"Número de comentarios cargados: {len(docs)}\")\n",
        "print(\"Primeros 3 comentarios:\")\n",
        "print(docs[:3])"
      ],
      "metadata": {
        "id": "QHUmJyjDdGNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1eb11d-9680-49e2-dcb7-a1edbd9da569"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de comentarios cargados: 1000\n",
            "Primeros 3 comentarios:\n",
            "['Wow... Loved this place.', 'Crust is not good.', 'Not tasty and the texture was just nasty.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(docs) == list   # Verifica que tu variable \"docs\" es una lista"
      ],
      "metadata": {
        "id": "L6WzrSrodG-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e07880-6c32-434d-a690-9fda63ce3fdd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)==1000  # verifica que la longitud de \"docs\" es de mil comentarios."
      ],
      "metadata": {
        "id": "QIK1u9WS2FtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf05ae5c-2e48-432c-9f6c-03b0c802f144"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0:10]     # observa algunos de los primeros comentarios"
      ],
      "metadata": {
        "id": "9AMLIfQvJqNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe8face0-00fc-4a02-9e62-9c02ad96567a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wow... Loved this place.',\n",
              " 'Crust is not good.',\n",
              " 'Not tasty and the texture was just nasty.',\n",
              " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
              " 'The selection on the menu was great and so were the prices.',\n",
              " 'Now I am getting angry and I want my damn pho.',\n",
              " \"Honeslty it didn't taste THAT fresh.)\",\n",
              " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
              " 'The fries were great too.',\n",
              " 'A great touch.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 2: sección de preguntas (regex).**   \n"
      ],
      "metadata": {
        "id": "k_ewoagic5jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Instrucciones:**\n",
        "\n",
        "###**A continuación deberás contestar cada una de las preguntas que te piden usando expresiones regulares (regex).**\n",
        "\n",
        "###**Por el momento no hay restricción en cuanto al número de líneas de código que agregues, pero trata de incluir las mínimas posibles.**"
      ],
      "metadata": {
        "id": "X-eMJa3DFCIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 1.**\n",
        "\n",
        "Busca y elimina todos los saltos de línea '\\n' que se encuentran al final de cada comentario.\n",
        "\n",
        "Una vez finalizado, imprime los primeros 10 comentarios del resultado obtenido.\n"
      ],
      "metadata": {
        "id": "78nJMemzn5a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "PwbYYIuZn8pE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Pregunta 1: Eliminar saltos de línea al final de cada comentario\n",
        "docs = [re.sub(r'\\n$', '', comment) for comment in docs]\n",
        "# Imprimir los primeros 10 comentarios del resultado obtenido\n",
        "print(\"Primeros 10 comentarios después de eliminar saltos de línea:\")\n",
        "print(docs[:10])"
      ],
      "metadata": {
        "id": "j-0qeh2Jn8l1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36a7dc3-f9ea-414d-d898-05794e5acd43"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeros 10 comentarios después de eliminar saltos de línea:\n",
            "['Wow... Loved this place.', 'Crust is not good.', 'Not tasty and the texture was just nasty.', 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.', 'The selection on the menu was great and so were the prices.', 'Now I am getting angry and I want my damn pho.', \"Honeslty it didn't taste THAT fresh.)\", 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.', 'The fries were great too.', 'A great touch.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 2.**  \n",
        "\n",
        "Busca e imprime todas las palabras que terminan con dos o más signos de admiración seguidos, por ejemplo \"!!!\".\n",
        "\n",
        "Debes imprimir tanto la palabra como la totalidad de signos de admiración que le siguen.\n",
        "\n",
        "Indica cuántos resultados obtuviste.\n",
        "\n"
      ],
      "metadata": {
        "id": "VWeKQC93ctEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "0p3kMXfddICc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "resultados = []\n",
        "for comment in docs:\n",
        "    # Buscar palabras que terminan con dos o más signos de admiración\n",
        "    #Usamos una expresion regular para encontrarlas\n",
        "    matches = re.findall(r'\\b\\w+!!+\\S*', comment)\n",
        "    resultados.extend(matches)\n",
        "# Imprimir las palabras encontradas y la cantidad de resultados\n",
        "print(\"Palabras que terminan con dos o más signos de admiración:\")\n",
        "print(resultados)\n",
        "print(f\"Número de resultados encontrados: {len(resultados)}\")"
      ],
      "metadata": {
        "id": "SPVM1MCWdH6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7efa4f6e-8521-4806-eb75-7343c34e49a8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que terminan con dos o más signos de admiración:\n",
            "['Firehouse!!!!!', 'APPETIZERS!!!', 'amazing!!!', 'buffet!!!', 'good!!', 'it!!!!', 'DELICIOUS!!', 'amazing!!', 'shawarrrrrrma!!!!!!', 'yucky!!!', 'steak!!!!!\"', 'delicious!!!', 'far!!', 'biscuits!!!', 'dry!!.', 'disappointing!!!', 'awesome!!', 'Up!!', 'FLY!!!!!!!!', 'here!!!\"\"\"', 'great!!!!!!!!!!!!!!', 'packed!!', 'otherwise!!\"', 'amazing!!!!!!!!!!!!!!!!!!!', 'style!!', 'disappointed!!']\n",
            "Número de resultados encontrados: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 3.**  \n",
        "\n",
        "Busca e imprime todas las palabras que están escritas totalmente en mayúsculas. Cada coincidencia debe ser una sola palabra.\n",
        "\n",
        "Indica cuántas palabras encontraste.\n",
        "\n"
      ],
      "metadata": {
        "id": "-s3okBqL96TT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "yKHJkZKo_nW5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "resultados_mayusculas = []\n",
        "for comment in docs:\n",
        "    # Buscar palabras en mayúsculas\n",
        "    matches = re.findall(r'\\b[A-Z]+\\b', comment)\n",
        "    resultados_mayusculas.extend(matches)\n",
        "# Imprimir las palabras encontradas y la cantidad de resultados\n",
        "print(\"Palabras escritas totalmente en mayúsculas:\")\n",
        "print(resultados_mayusculas)\n",
        "print(f\"Número de palabras encontradas: {len(resultados_mayusculas)}\")"
      ],
      "metadata": {
        "id": "L3q08aq69sNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b75276-7ca0-49cf-b690-0925bc8a2c13"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras escritas totalmente en mayúsculas:\n",
            "['I', 'I', 'THAT', 'A', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'APPETIZERS', 'A', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'WILL', 'NEVER', 'EVER', 'STEP', 'FORWARD', 'IN', 'IT', 'AGAIN', 'I', 'LOVED', 'I', 'AND', 'REAL', 'I', 'I', 'I', 'I', 'BITCHES', 'I', 'I', 'I', 'I', 'NYC', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'STALE', 'I', 'I', 'DELICIOUS', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'WORST', 'EXPERIENCE', 'EVER', 'I', 'ALL', 'I', 'BARGAIN', 'I', 'TV', 'NONE', 'I', 'M', 'FREEZING', 'AYCE', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'FLAVOR', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'NEVER', 'I', 'I', 'I', 'I', 'BBQ', 'I', 'A', 'I', 'UNREAL', 'I', 'I', 'I', 'I', 'I', 'I', 'OMG', 'I', 'BETTER', 'I', 'I', 'BLAND', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'RUDE', 'INCONSIDERATE', 'MANAGEMENT', 'I', 'I', 'WILL', 'NEVER', 'EVER', 'GO', 'BACK', 'AND', 'HAVE', 'TOLD', 'MANY', 'PEOPLE', 'WHAT', 'HAD', 'HAPPENED', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'TOTAL', 'WASTE', 'OF', 'TIME', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'FS', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'AZ', 'I', 'I', 'I', 'I', 'LOVED', 'I', 'I', 'I', 'I', 'I', 'I', 'CONCLUSION', 'I', 'I', 'I', 'I', 'I', 'I', 'BEST', 'I', 'GO', 'NOW', 'A', 'I', 'I', 'GC', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'AVOID', 'THIS', 'ESTABLISHMENT', 'I', 'I', 'I', 'A', 'I', 'I', 'AN', 'HOUR', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'NASTY', 'OMG', 'I', 'I', 'NO', 'I', 'I', 'I', 'BEST', 'I', 'I', 'I', 'I', 'THE', 'OWNERS', 'REALLY', 'REALLY', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'PERFECT', 'SCREAMS', 'LEGIT', 'I', 'MGM', 'I', 'I', 'I', 'A', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'BEST', 'I', 'I', 'T', 'A', 'FLY', 'A', 'FLY', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'FANTASTIC', 'I', 'I', 'I', 'I', 'GREAT', 'OK', 'I', 'I', 'WAY', 'I', 'I', 'MUST', 'HAVE', 'I', 'I', 'I', 'I', 'I', 'I', 'OK', 'I', 'I', 'I', 'I', 'OVERPRICED', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'BARE', 'HANDS', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'WEAK', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'SHOULD', 'I', 'I', 'I', 'RI', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'VERY', 'I', 'I', 'I', 'NOT', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'A', 'I', 'I', 'I', 'I', 'I', 'I']\n",
            "Número de palabras encontradas: 455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 4.**  \n",
        "\n",
        "Busca e imprime los comentarios en donde todos los caracteres alfabéticos (letras) están en mayúsculas.\n",
        "\n",
        "Cada coincidencia encontrada debe ser todo el comentario/enunciado.\n",
        "\n",
        "Indica cuántos resultados obtuviste.\n"
      ],
      "metadata": {
        "id": "GX8eYyDoMZma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "K8VuZxvTMYj6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "resultados_comentarios_mayusculas = []\n",
        "for comment in docs:\n",
        "    # Verificar si el comentario está en mayúsculas\n",
        "    if re.match(r'^[A-Z\\s\\W]*$', comment):\n",
        "        resultados_comentarios_mayusculas.append(comment)\n",
        "# Imprimir los comentarios encontrados y la cantidad de resultados\n",
        "print(\"Comentarios donde todos los caracteres alfabéticos están en mayúsculas:\")\n",
        "print(resultados_comentarios_mayusculas)\n",
        "print(f\"Número de comentarios encontrados: {len(resultados_comentarios_mayusculas)}\")"
      ],
      "metadata": {
        "id": "PmKgX7sCMcDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcdc43f1-1942-4103-cbe2-53f893e75f9d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comentarios donde todos los caracteres alfabéticos están en mayúsculas:\n",
            "['DELICIOUS!!', 'RUDE & INCONSIDERATE MANAGEMENT.', 'WILL NEVER EVER GO BACK AND HAVE TOLD MANY PEOPLE WHAT HAD HAPPENED.', 'TOTAL WASTE OF TIME.', 'AVOID THIS ESTABLISHMENT!']\n",
            "Número de comentarios encontrados: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 5.**  \n",
        "\n",
        "Busca e imprime todas las palabras que tengan una vocal acentuada, del tipo á, é, í, ó, ú.\n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "a1i6qv7-McmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "nZZ5zKUOMeGD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "resultados_vocales_acentuadas = []\n",
        "for comment in docs:\n",
        "    # Buscar palabras con vocales acentuadas/mediante expresiones regulares para su busqueda\n",
        "    matches = re.findall(r'\\b\\w*[áéíóú]\\w*\\b', comment)\n",
        "    resultados_vocales_acentuadas.extend(matches)\n",
        "# Imprimir las palabras encontradas y la cantidad de resultados\n",
        "print(\"Palabras que contienen vocales acentuadas:\")\n",
        "print(resultados_vocales_acentuadas)\n",
        "print(f\"Número de palabras encontradas: {len(resultados_vocales_acentuadas)}\")"
      ],
      "metadata": {
        "id": "l1mFvUEZMe8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bad8bf1-3df4-4558-8eb6-f373424310f8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que contienen vocales acentuadas:\n",
            "['fiancé', 'Café', 'puréed']\n",
            "Número de palabras encontradas: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 6.**  \n",
        "\n",
        "Busca e imprime todas las cantidades numéricas monetarias, enteras o con decimales, que inician con el símbolo $\\$$.\n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "ZmPiAI82Mfb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "6vhe9-Y-MhL9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_monetarios = []\n",
        "for comment in docs:\n",
        "    # Buscar cantidades monetarias\n",
        "    matches = re.findall(r'\\$\\d+(?:\\.\\d{1,2})?', comment)\n",
        "    resultados_monetarios.extend(matches)\n",
        "# Imprimir las cantidades encontradas y la cantidad de resultados\n",
        "print(\"Cantidades numéricas monetarias encontradas:\")\n",
        "print(resultados_monetarios)\n",
        "print(f\"Número de cantidades encontradas: {len(resultados_monetarios)}\")"
      ],
      "metadata": {
        "id": "_t0a5xWDMhQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171dfbab-389f-4951-d344-aed2ef3d88d2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidades numéricas monetarias encontradas:\n",
            "['$20', '$4.00', '$17', '$3', '$35', '$7.85', '$12', '$11.99']\n",
            "Número de cantidades encontradas: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 7.**  \n",
        "\n",
        "Busca e imprime todas las palabras que sean variantes de la palabra \"love\", sin importar si incluyen mayúsculas o minúsculas, o la manera en que esté conjugada o alguna otra variación que se haga con dicha palabra.\n",
        "\n",
        "Indica cuántos resultados obtuviste."
      ],
      "metadata": {
        "id": "2j-HpvhwMhq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "kqqyRChVMjol"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_love = []\n",
        "for comment in docs:  # Usamos la lista que ya tenías sin saltos de línea\n",
        "    # Buscar variantes de la palabra \"love\" sin importar mayúsculas/minúsculas\n",
        "    matches = re.findall(r'\\blove\\w*\\b', comment, re.IGNORECASE)\n",
        "    resultados_love.extend(matches)\n",
        "\n",
        "# Imprimir las palabras encontradas y la cantidad de resultados\n",
        "print(\"Palabras encontradas que son variantes de 'love':\")\n",
        "print(resultados_love)\n",
        "print(f\"Número de palabras encontradas: {len(resultados_love)}\")"
      ],
      "metadata": {
        "id": "UXd0VQluMj_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ecdadf-20fe-440a-85e2-84b7c21d3f59"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras encontradas que son variantes de 'love':\n",
            "['Loved', 'loved', 'Loved', 'love', 'loves', 'LOVED', 'lovers', 'love', 'lovers', 'Love', 'loved', 'loved', 'love', 'love', 'love', 'loved', 'love', 'loved', 'Love', 'LOVED', 'love', 'lovely', 'love', 'lovely', 'love', 'lover', 'loved', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love']\n",
            "Número de palabras encontradas: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 8.**  \n",
        "\n",
        "Busca e imprime todas las palabras, variantes de \"so\" y \"good\", que tengan dos o más \"o\" en \"so\" y 3 o más \"o\" en good.\n",
        "\n",
        "Indica cuántas encontraste.\n"
      ],
      "metadata": {
        "id": "Ctb-NTY3MkYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "A8Nf3B_cMlqg"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_so_good = []\n",
        "\n",
        "for comment in docs:\n",
        "    # Buscar variantes de \"so\" con dos o más 'o' seguidas\n",
        "    matches_so = re.findall(r'\\bso{2,}\\b', comment, re.IGNORECASE)\n",
        "\n",
        "    # Buscar variantes de \"good\" con tres o más 'o' seguidas\n",
        "    matches_good = re.findall(r'\\bgo{3,}d\\b', comment, re.IGNORECASE)\n",
        "\n",
        "    resultados_so_good.extend(matches_so)\n",
        "    resultados_so_good.extend(matches_good)\n",
        "\n",
        "# Imprimir resultados y cantidad total\n",
        "print(\"Palabras variantes de 'so' y 'good' encontradas:\")\n",
        "print(resultados_so_good)\n",
        "print(f\"Número total de palabras encontradas: {len(resultados_so_good)}\")\n"
      ],
      "metadata": {
        "id": "svS4-vvPMl6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a0253b2-e0a4-4e2c-fa1d-1bb47ea76c85"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras variantes de 'so' y 'good' encontradas:\n",
            "['Sooooo', 'soooo', 'soooooo', 'soooo']\n",
            "Número total de palabras encontradas: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 9.**  \n",
        "\n",
        "Busca e imprime todas las palabras que tengan una longitud mayor estrictamente a 10 caracteres alfabéticos.\n",
        "\n",
        "No se consideran los signos de puntuación o caracteres especiales en la longitud de estas cadenas, solo caracteres alfabéticos en mayúsculas o minúsculas.\n",
        "\n",
        "Indica la cantidad de palabras encontradas.\n"
      ],
      "metadata": {
        "id": "hkak1opjMmlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "PYxdp3uhMoD0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "resultados_longitud = []\n",
        "for comment in docs:\n",
        "    # Buscar palabras solo con caracteres alfabéticos, de longitud estrictamente > 10\n",
        "    matches = re.findall(r'\\b[a-zA-Z]{11,}\\b', comment)\n",
        "    resultados_longitud.extend(matches)\n",
        "\n",
        "print(\"Palabras con más de 10 caracteres alfabéticos:\")\n",
        "print(resultados_longitud)\n",
        "print(f\"Número de palabras encontradas: {len(resultados_longitud)}\\n\")"
      ],
      "metadata": {
        "id": "BR7e2F4FMof-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926ff460-e79a-42d4-d761-0b06d2358daf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras con más de 10 caracteres alfabéticos:\n",
            "['recommendation', 'recommended', 'overwhelmed', 'inexpensive', 'establishment', 'imaginative', 'opportunity', 'experiencing', 'underwhelming', 'relationship', 'unsatisfying', 'disappointing', 'outrageously', 'disappointing', 'expectations', 'restaurants', 'suggestions', 'disappointed', 'considering', 'Unfortunately', 'immediately', 'ingredients', 'accommodations', 'maintaining', 'Interesting', 'disrespected', 'accordingly', 'unbelievable', 'cheeseburger', 'descriptions', 'inexpensive', 'disappointed', 'Veggitarian', 'outstanding', 'recommendation', 'disappointed', 'disappointed', 'neighborhood', 'disappointed', 'corporation', 'considering', 'exceptional', 'shawarrrrrrma', 'disappointed', 'vinaigrette', 'immediately', 'unbelievably', 'replenished', 'disappointed', 'enthusiastic', 'Outstanding', 'comfortable', 'interesting', 'INCONSIDERATE', 'considering', 'transcendant', 'disappointment', 'disappointed', 'disappointed', 'overwhelmed', 'professional', 'Furthermore', 'combination', 'connoisseur', 'profiterole', 'outstanding', 'acknowledged', 'ventilation', 'beautifully', 'establishment', 'extraordinary', 'disappointed', 'cheesecurds', 'disappointed', 'interesting', 'experienced', 'opportunity', 'disgraceful', 'restaurants', 'ESTABLISHMENT', 'recommended', 'disappointed', 'recommended', 'acknowledged', 'presentation', 'Philadelphia', 'disappointed', 'disappointing', 'grandmother', 'drastically', 'informative', 'Disappointed', 'constructed', 'comfortable', 'Smashburger', 'cheeseburger', 'neighborhood', 'disappointed', 'hospitality', 'recommending', 'disappointed', 'deliciously', 'compliments', 'recommendation', 'establishment', 'calligraphy', 'traditional', 'combination', 'Unfortunately', 'Wienerschnitzel', 'unfortunately', 'considering', 'highlighted', 'Mediterranean', 'unprofessional', 'anticipated', 'disappointing', 'unexperienced', 'disrespected', 'professional', 'restaurants', 'Disappointing', 'WAAAAAAyyyyyyyyyy', 'reservation', 'imagination', 'undercooked', 'disappointed', 'disappointment', 'disappointment', 'deuchebaggery', 'disappointed', 'disappointment', 'immediately', 'Unfortunately', 'disapppointment', 'circumstances', 'undercooked', 'caterpillar', 'presentation', 'disappointed', 'underwhelming']\n",
            "Número de palabras encontradas: 141\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 10.**  \n",
        "\n",
        "Busca e imprime todas las palabras que inician con una letra mayúscula y terminan con una minúscula, pero que además no sea la primera palabra del comentario/string.\n",
        "\n",
        "Indica la cantidad de resultados obtenidos."
      ],
      "metadata": {
        "id": "ApjTNzSxMpDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "Vb0ndRGAMqdL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_may_min = []\n",
        "for comment in docs:\n",
        "    # Dividir el comentario en palabras respetando la posición (para ignorar la primera)\n",
        "    palabras = comment.split()\n",
        "    # Recorrer desde la segunda palabra (índice 1)\n",
        "    for palabra in palabras[1:]:\n",
        "        # Buscar palabras que inician con mayúscula y terminan con minúscula (solo una palabra a la vez)\n",
        "        if re.match(r'^[A-Z].*[a-z]$', palabra):\n",
        "            resultados_may_min.append(palabra)\n",
        "\n",
        "print(\"Palabras que inician con mayúscula y terminan con minúscula (no primeras palabras):\")\n",
        "print(resultados_may_min)\n",
        "print(f\"Número de palabras encontradas: {len(resultados_may_min)}\\n\")"
      ],
      "metadata": {
        "id": "dLPTRPnTMqqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a626a3ee-c0cf-4e3b-fedd-9fe33baeaaa8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que inician con mayúscula y terminan con minúscula (no primeras palabras):\n",
            "['Loved', 'May', 'Rick', 'Steve', 'Cape', 'Cod', 'Burrittos', 'The', 'They', 'Mexican', 'Luke', 'Our', 'Hiro', 'Greek', 'Greek', 'Heart', 'Attack', 'Grill', 'Vegas', 'Dos', 'Jeff', 'Very', 'Bad', 'Customer', 'Service', \"I've\", 'Vegas', 'Rice', 'Pho', 'Hard', 'Rock', 'Casino', 'Buffet', 'Tigerlilly', 'Yama', 'Thai', 'Indian', 'Not', \"I'll\", \"I'm\", 'Lox', 'Subway', 'Mandalay', 'Great', 'Voodoo', \"I'd\", 'Phoenix', 'Vegas', 'Khao', 'Soi', \"I'm\", 'Lemon', \"Joey's\", 'Valley', 'Phoenix', 'Fridays', \"I've\", 'Jamaican', 'Bussell', 'Filet', 'Otto', \"M's\", 'Not', 'Greek', 'Veggitarian', 'Madison', 'Jenni', 'Bachi', 'Burger', 'Pizza', 'They', 'Bachi', \"I'd\", 'English', \"I've\", \"I've\", 'Pizza', 'Hut', 'Seat', \"I've\", 'Vegas.....there', 'Gordon', \"Ramsey's\", 'Steak', \"I've\", 'Outstanding', 'Best', 'Food', \"I'll\", 'Lobster', 'Bisque', 'Eggplant', 'Green', 'Bean', \"I'm\", 'Vegas', 'Vegas', 'Crystals', 'Ians', \"I'm\", 'San', 'Francisco', 'Bay', 'Buldogis', 'Gourmet', 'Hot', 'Dog', \"I'm\", \"I've\", 'Steiners', \"I'll\", \"Carly's\", 'Vegas', 'Camelback', 'Flower', 'Shop', 'Cartel', 'Las', \"I've\", 'Very', \"Mom's\", 'Vegas', 'Mexican', \"I'm\", 'Perfect', 'Vegas', 'This', \"I'm\", 'Thai', \"I'll\", 'Thai', 'Crema', 'North', 'Bloody', 'Pho', 'Caesar', 'Macarons', 'Very', 'Disappointed', 'Big', 'Bay', 'Italian', 'Baba', 'Ganoush', 'Smashburger', \"I've\", \"I'm\", 'Panna', 'Cotta', 'Mango', 'Pineapple', 'Delight', \"I've\", 'The', 'Strip', 'Paradise', 'Valley', 'Cibo', 'Thumbs', 'Italian', 'Pros', 'Large', 'Nice', 'Great', 'The', 'Elk', 'Filet', 'Dylan', 'All', 'Han', 'Nan', 'Chicken', 'Bar', 'Edinburgh', 'Chinese', \"I've\", 'Indian', 'Chinese', \"I'm\", \"I'll\", 'Prices', 'Phoenix', 'Both', 'Hot', 'Sour', 'Egg', 'Flower', 'Soups', 'Sunday', 'Hunan', 'The', \"I'm\", 'Pita', 'Wienerschnitzel', 'Maine', 'Lobster', 'Roll', \"I'm\", 'Kabuki', 'Maria', \"Caballero's\", \"I'm\", 'Wife', \"I've\", \"I've\", \"I'm\", 'To', 'Place', 'Japanese', 'Albondigas', 'Mediterranean', 'Chicken', 'Salad', 'Mellow', 'Thai', 'Vegas', 'Buffet', 'Bellagio', 'Vegas', 'Christmas', 'Eve', 'Vegetarian', \"I've\", 'Taco', 'Heimer', 'Ha', 'Long', 'Bay', 'Subway', 'When', 'In', 'Ninja', 'Sushi']\n",
            "Número de palabras encontradas: 233\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 11.**  \n",
        "\n",
        "Busca e imprime la secuencia de dos o más palabras que están separadas por un guion, \"-\", sin que tengan espacios en blanco entre ellas.\n",
        "\n",
        "Por ejemplo \"Go-Kart\" sería válido, pero \"Go  -Kart\" o \"Go  -  Kart\" no lo serían.\n",
        "\n",
        "Indica la cantidad de resultados obtenidos."
      ],
      "metadata": {
        "id": "u7nfm4KhMrNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "OwU-a7eGMsub"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_guion = []\n",
        "for comment in docs:\n",
        "    # Buscar secuencia de dos o más palabras unidas con guion, sin espacios\n",
        "    # Cada palabra tiene al menos una letra (mayúscula o minúscula)\n",
        "    matches = re.findall(r'\\b[a-zA-Z]+(?:-[a-zA-Z]+)+\\b', comment)\n",
        "    resultados_guion.extend(matches)\n",
        "\n",
        "print(\"Secuencias de dos o más palabras unidas por guion sin espacios:\")\n",
        "print(resultados_guion)\n",
        "print(f\"Número de resultados encontrados: {len(resultados_guion)}\")"
      ],
      "metadata": {
        "id": "SgzIL74ZMtGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4804cf1-d55c-4c0e-80f0-0ce170c93ee8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secuencias de dos o más palabras unidas por guion sin espacios:\n",
            "['flat-lined', 'hands-down', 'must-stop', 'sub-par', 'Service-check', 'in-house', 'been-stepped-in-and-tracked-everywhere', 'multi-grain', 'to-go', 'non-customer', 'High-quality', 'sit-down', 'over-whelm', 'low-key', 'non-fancy', 'golden-crispy', 'over-priced', 'over-hip', 'under-services']\n",
            "Número de resultados encontrados: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 12.**  \n",
        "\n",
        "Busca e imprime todas las palabras que terminan en \"ing\" o \"ed\".\n",
        "\n",
        "Indica la cantidad de palabras que encontraste de cada una."
      ],
      "metadata": {
        "id": "DEIgl79HMthr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "I4TSofBMMv9y"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_ing = []\n",
        "palabras_ed = []\n",
        "\n",
        "for comment in docs:\n",
        "    # Buscar palabras que terminan en \"ing\"\n",
        "    matches_ing = re.findall(r'\\b\\w+ing\\b', comment, re.IGNORECASE)\n",
        "    palabras_ing.extend(matches_ing)\n",
        "\n",
        "    # Buscar palabras que terminan en \"ed\"\n",
        "    matches_ed = re.findall(r'\\b\\w+ed\\b', comment, re.IGNORECASE)\n",
        "    palabras_ed.extend(matches_ed)\n",
        "\n",
        "print(\"Palabras que terminan en 'ing':\")\n",
        "print(palabras_ing)\n",
        "print(f\"Número de palabras que terminan en 'ing': {len(palabras_ing)}\\n\")\n",
        "\n",
        "print(\"Palabras que terminan en 'ed':\")\n",
        "print(palabras_ed)\n",
        "print(f\"Número de palabras que terminan en 'ed': {len(palabras_ed)}\")"
      ],
      "metadata": {
        "id": "AhGq6De2Mvyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c3dc512-af19-4e0e-85ee-12361acc2b46"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que terminan en 'ing':\n",
            "['during', 'getting', 'being', 'being', 'amazing', 'running', 'redeeming', 'getting', 'thing', 'dressing', 'refreshing', 'running', 'amazing', 'nothing', 'appalling', 'wasting', 'eating', 'going', 'Coming', 'experiencing', 'underwhelming', 'eating', 'raving', 'spring', 'unsatisfying', 'amazing', 'Everything', 'disappointing', 'dining', 'flirting', 'thing', 'coming', 'playing', 'ordering', 'arriving', 'disappointing', 'preparing', 'loving', 'liking', 'reviewing', 'venturing', 'including', 'during', 'changing', 'going', 'considering', 'coming', 'going', 'everything', 'looking', 'dressing', 'dining', 'Everything', 'amazing', 'judging', 'maintaining', 'asking', 'having', 'something', 'lacking', 'Interesting', 'preparing', 'missing', 'feeling', 'exceeding', 'inviting', 'climbing', 'waiting', 'coming', 'being', 'lacking', 'going', 'amazing', 'dealing', 'annoying', 'falling', 'sporting', 'amazing', 'providing', 'building', 'FREEZING', 'lighting', 'going', 'nothing', 'working', 'eating', 'dressing', 'being', 'outstanding', 'getting', 'amazing', 'rating', 'eating', 'writing', 'everything', 'dining', 'boring', 'charming', 'going', 'making', 'pricing', 'considering', 'amazing', 'Everything', 'nothing', 'nothing', 'driving', 'during', 'evening', 'Outstanding', 'buying', 'handling', 'wasting', 'craving', 'dining', 'interesting', 'amazing', 'being', 'outshining', 'starving', 'coming', 'considering', 'shopping', 'nothing', 'getting', 'trying', 'eating', 'going', 'everything', 'Nothing', 'going', 'outstanding', 'running', 'forgetting', 'upgrading', 'eating', 'bring', 'hoping', 'living', 'dining', 'filling', 'amazing', 'Everything', 'thing', 'amazing', 'Everything', 'interesting', 'amazing', 'amazing', 'waiting', 'going', 'going', 'dining', 'saving', 'something', 'trying', 'disgusting', 'hankering', 'being', 'being', 'being', 'setting', 'sitting', 'waiting', 'satisfying', 'eating', 'being', 'freaking', 'getting', 'amazing', 'disappointing', 'seasoning', 'going', 'being', 'bring', 'letting', 'evening', 'waiting', 'being', 'eating', 'going', 'seating', 'playing', 'amazing', 'staying', 'giving', 'talking', 'amazing', 'amazing', 'amazing', 'amazing', 'filling', 'dripping', 'going', 'serving', 'recommending', 'thing', 'reading', 'seating', 'going', 'everything', 'thing', 'sitting', 'waiting', 'bring', 'revisiting', 'coming', 'anything', 'feeling', 'during', 'thing', 'being', 'amazing', 'being', 'amazing', 'satifying', 'describing', 'coming', 'everything', 'Paying', 'going', 'thing', 'amazing', 'getting', 'cramming', 'considering', 'fucking', 'going', 'appealing', 'getting', 'coming', 'Everything', 'dealing', 'everything', 'something', 'during', 'dining', 'cooking', 'dining', 'editing', 'setting', 'amazing', 'rotating', 'Pricing', 'satisfying', 'disappointing', 'amazing', 'returning', 'running', 'being', 'thing', 'nothing', 'poisoning', 'thinking', 'something', 'going', 'disgusting', 'caring', 'bring', 'Disappointing', 'saying', 'going', 'coming', 'building', 'seating', 'dipping', 'setting', 'anything', 'drinking', 'serving', 'doing', 'putting', 'getting', 'looking', 'coming', 'staying', 'lacking', 'underwhelming', 'drawing', 'bring']\n",
            "Número de palabras que terminan en 'ing': 280\n",
            "\n",
            "Palabras que terminan en 'ed':\n",
            "['Loved', 'Stopped', 'loved', 'ended', 'overpriced', 'tried', 'disgusted', 'shocked', 'recommended', 'performed', 'red', 'asked', 'overwhelmed', 'grossed', 'melted', 'provided', 'cooked', 'ordered', 'realized', 'Loved', 'lined', 'cooked', 'ripped', 'ripped', 'petrified', 'included', 'expected', 'seasoned', 'cheated', 'walked', 'smelled', 'tailored', 'arrived', 'roasted', 'added', 'LOVED', 'cooked', 'passed', 'liked', 'managed', 'served', 'overpriced', 'checked', 'disappointed', 'red', 'decorated', 'served', 'watched', 'greeted', 'seated', 'waited', 'flavored', 'ordered', 'ordered', 'relocated', 'impressed', 'seated', 'priced', 'treated', 'ordered', 'used', 'handed', 'listed', 'missed', 'thrilled', 'inspired', 'desired', 'overcooked', 'decided', 'looked', 'dressed', 'treated', 'ordered', 'sucked', 'expected', 'sucked', 'imagined', 'served', 'arrived', 'satisfied', 'voted', 'insulted', 'disrespected', 'dreamed', 'lived', 'stepped', 'mixed', 'showed', 'realized', 'loved', 'needed', 'loved', 'wrapped', 'uninspired', 'Ordered', 'uploaded', 'covered', 'supposed', 'rolled', 'stayed', 'Based', 'received', 'privileged', 'charged', 'visited', 'proclaimed', 'disappointed', 'Stopped', 'dedicated', 'liked', 'disappointed', 'waited', 'waited', 'burned', 'waited', 'disappointed', 'Waited', 'disappointed', 'pulled', 'prepared', 'fried', 'passed', 'ordered', 'toasted', 'untoasted', 'figured', 'returned', 'eyed', 'disappointed', 'pleased', 'replenished', 'disappointed', 'treated', 'offered', 'tasted', 'dropped', 'decorated', 'served', 'HAPPENED', 'walked', 'stuffed', 'located', 'Cooked', 'disappointed', 'screwed', 'frustrated', 'iced', 'stuffed', 'disappointed', 'grossed', 'enjoyed', 'looked', 'overwhelmed', 'stayed', 'smeared', 'stepped', 'tracked', 'tried', 'rushed', 'loved', 'Ordered', 'cooked', 'insulted', 'contained', 'enjoyed', 'relaxed', 'loved', 'acknowledged', 'trimmed', 'cooked', 'claimed', 'handled', 'LOVED', 'asked', 'limited', 'boiled', 'liked', 'sliced', 'attached', 'humiliated', 'fried', 'impressed', 'disappointed', 'priced', 'disappointed', 'need', 'need', 'experienced', 'waited', 'seated', 'decided', 'pleased', 'recommended', 'helped', 'witnessed', 'Waited', 'waited', 'waited', 'checked', 'tasted', 'disappointed', 'served', 'rated', 'recommended', 'pulled', 'waited', 'acknowledged', 'perpared', 'dusted', 'powdered', 'enjoyed', 'expanded', 'ended', 'arrived', 'wanted', 'disappointed', 'need', 'checked', 'impressed', 'reheated', 'tasted', 'grilled', 'focused', 'roasted', 'asked', 'ignored', 'tasted', 'Ordered', 'greeted', 'seated', 'Tried', 'seated', 'Disappointed', 'ordered', 'constructed', 'fried', 'requested', 'used', 'tasted', 'drenched', 'tried', 'walked', 'expected', 'disappointed', 'mortified', 'impressed', 'refrained', 'pleased', 'loved', 'grilled', 'reminded', 'sucked', 'hooked', 'ordered', 'disappointed', 'seasoned', 'added', 'touched', 'fried', 'opened', 'impressed', 'watched', 'Tasted', 'ordered', 'received', 'impressed', 'overcooked', 'cooked', 'needed', 'served', 'ordered', 'overpriced', 'OVERPRICED', 'packed', 'opposed', 'priced', 'surprised', 'focused', 'overpriced', 'tried', 'enjoyed', 'qualified', 'tasted', 'hated', 'watched', 'fried', 'tried', 'helped', 'started', 'highlighted', 'used', 'enjoyed', 'ordered', 'tasted', 'asked', 'refused', 'tried', 'toasted', 'anticipated', 'unexperienced', 'insulted', 'disrespected', 'impressed', 'puréed', 'asked', 'rated', 'lacked', 'sliced', 'pulled', 'undercooked', 'seemed', 'watered', 'lacked', 'disappointed', 'overpriced', 'ensued', 'disappointed', 'placed', 'avoided', 'received', 'wanted', 'sucked', 'happened', 'owned', 'wanted', 'Overpriced', 'vomited', 'started', 'unwrapped', 'lacked', 'seemed', 'undercooked', 'closed', 'refried', 'dried', 'disappointed', 'impressed', 'wasted', 'poured']\n",
            "Número de palabras que terminan en 'ed': 339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte 3. Proceso de limpieza.**"
      ],
      "metadata": {
        "id": "70StdqAZa9E9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 13.**  \n",
        "\n",
        "Ahora realiza un proceso de limpieza del corpus que incluya los siguientes procesos:\n",
        "\n",
        "*   Solo se deben considerar caracteres alfabéticos. Es decir, se eliminan todos los signos de puntuación y caracteres especiales.\n",
        "*   Todos los caracteres alfabéticos se transforman a minúsculas.\n",
        "*   Se deben eliminar todos los espacios en blanco adicionales que se puedan encontrar en cada comentario.\n",
        "\n",
        "Al finalizar dicho proceso de limpieza, imprime el resultado de los primeros 10 comentarios resultantes.\n",
        "   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xaDUFXHrMvX2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K3kQzPOPMx0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mYEDlHSFMyJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 14.**  \n",
        "\n",
        "Con el resultado de la limpieza obtenido en la pregunta anterior, realiza ahora un proceso de tokenización por palabras del corpus.\n",
        "\n",
        "Es decir, al final de este proceso de tokenización, debes tener como resultado una lista de listas, donde cada comentario estará tokenizado por palabras.\n",
        "\n",
        "Al terminar calcula el total de tokens obtenido en todo el corpus."
      ],
      "metadata": {
        "id": "WZwEhg2lUSAX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kbAL9-v0V-jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZs_etmiV-fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Pregunta 15.**  \n",
        "\n",
        "Finalmente, en este ejercicio definiremos nuestro conjunto de palabras \"stopwords\", las cuales deberás eliminar de todo el corpus.\n",
        "\n",
        "Recuerda que ejemplos de stopwords son artículos, adverbios, conectivos, etcétera, que tienen frecuencias de aparición muy altas en cualquier documento, pero que no brindan mucho significado en cuanto al significado de un enunciado.\n",
        "\n",
        "Con base a la lista de stopwords que se te proporciona, realiza un proceso de limpieza eliminando todas estas palabras del corpus obtenido en el ejercicio anterior.\n",
        "\n",
        "Obtener cuántos tokens/palabras quedan finalmente en todo el corpus.\n",
        "\n",
        "Obtener cuántos de estos tokens/palabras son diferentes, es decir, cuántos tokens únicos tendrá lo que llamaremos más adelante nuestro vocabulario."
      ],
      "metadata": {
        "id": "EFeu0OJ7WDPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Considera la siguiente lista como tu conjunto de stopwords:\n",
        "mis_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', 'now', 'll']"
      ],
      "metadata": {
        "id": "6FP4FF3KXGxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CD8yjyq1ZrwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ZPi5prKZro5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Comentarios**\n",
        "\n",
        "Incluye finalmente tus comentarios de la actividad."
      ],
      "metadata": {
        "id": "NDbKkuxRbLoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<< incluye aquí tus comentarios >>"
      ],
      "metadata": {
        "id": "o7fzbvqVbUGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Fin de la Actividad de la semana 2.**"
      ],
      "metadata": {
        "id": "PHaKw_6Ldbaf"
      }
    }
  ]
}